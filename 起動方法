事前準備
・Ollama 本体
・Ollama内でgpt-oss:20bをダウンロード
・サーバー本体となるPCのIPアドレスを192.168.1.76:3001に変更する（ローカル証明書のため）
・NEXT.jsで新しいプロジェクトを作成してフロントエンドを格納する
・必要なPhtonライブラリをインストール
・以下のコマンドをそれぞれのウィンドウで実行（単一のウィンドウでは実行しないこと）

cd ~/interview-ai/backend
source .venv/bin/activate
export WHISPER_MODEL=large-v3
export WHISPER_DEVICE=cuda
export WHISPER_COMPUTE_TYPE=int8_float16
export LD_LIBRARY_PATH="/home/yamagataai/interview-ai/backend/.venv/lib/python3.10/site-packages/nvidia/cublas/lib:/home/yamagataai/interview-ai/backend/.venv/lib/python3.10/site-packages/nvidia/cudnn/lib:$LD_LIBRARY_PATH"
CUDA_VISIBLE_DEVICES=0 python main.py

ollama run gpt-oss:20b

cd ~/interview-ai/frontend
npm run dev:https
